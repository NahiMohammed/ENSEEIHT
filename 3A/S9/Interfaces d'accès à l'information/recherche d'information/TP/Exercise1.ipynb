{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVrcHNZpQLUz"
   },
   "source": [
    "# Exercices\n",
    " \n",
    "- Les \"fake news\" sont des informations erronées ou des désinformations diffusées dans le pays par le bouche-à-oreille et, plus récemment, par les communications numériques tels que les messages de l'application \"What's app\", les messages des médias sociaux, etc.\n",
    "\n",
    "- Les fake News se propagent plus rapidement que les vraies News et créent des problèmes et des craintes au sein des groupes et de la société.\n",
    "\n",
    "- Nous allons nous attaquer à ces problèmes en utilisant des techniques NLP, l'objectif est de prédire (classer)  si un message/texte donné est **un vrai ou un faux message**.\n",
    " \n",
    "L'objectif est de comparer différentes approches de représentation de textes :\n",
    "- codage de textes simple tf.idf, simple comptage\n",
    "- codage wordembeddings\n",
    "- codage par des transformers\n",
    "\n",
    "et différentes approches de de classification \n",
    "- méthode classique (tRegression logistoc, un KNN, ...), bibliothèques : pytorch ou SKLEARN\n",
    "- méthode basée sur les tranfomers\n",
    "- - utilisation d'un pipeline (tout prêt)\n",
    "  - utitisation d'un modèle avec votre propre finetuning\n",
    "\n",
    "sur deux dataset différents un en francais le second en anglais.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wU5KDovsV9ez",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Le dataset FakeNews**\n",
    "- Ces données se composent de trois colonnes : Titre, Texte,  Label\n",
    "- Le texte est une déclaration ou un message concernant un événement ou une situation particulière.\n",
    "- La caractéristique label indique si le texte donné est faux ou réel.\n",
    "- Comme il n'y a que deux classes (Fake ou Réel) , ce problème relève de la classification binaire.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 : Classification classique avec différentes représentations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset en anglais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Three more states refuse Trump commission's vo...</td>\n",
       "      <td>WASHINGTON (Reuters) - Maryland, Delaware and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump Crosses The Line, Attacks Civil Rights ...</td>\n",
       "      <td>Georgia Congressman John Lewis is one of Ameri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IS TRUMP A RACIST? Famous Italian-American “Ge...</td>\n",
       "      <td>Robert Davi gives a great answer to Neil Cavut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ted Cruz Gets His Unethical A** Handed To Him...</td>\n",
       "      <td>Seth Meyers destroyed Republican presidential ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Putin says Trump hampered from delivering elec...</td>\n",
       "      <td>SOCHI, Russia (Reuters) - Russian President Vl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Three more states refuse Trump commission's vo...   \n",
       "1   Trump Crosses The Line, Attacks Civil Rights ...   \n",
       "2  IS TRUMP A RACIST? Famous Italian-American “Ge...   \n",
       "3   Ted Cruz Gets His Unethical A** Handed To Him...   \n",
       "4  Putin says Trump hampered from delivering elec...   \n",
       "\n",
       "                                                text  label  \n",
       "0  WASHINGTON (Reuters) - Maryland, Delaware and ...      1  \n",
       "1  Georgia Congressman John Lewis is one of Ameri...      0  \n",
       "2  Robert Davi gives a great answer to Neil Cavut...      0  \n",
       "3  Seth Meyers destroyed Republican presidential ...      0  \n",
       "4  SOCHI, Russia (Reuters) - Russian President Vl...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "#read the dataset with name \"data_fake_news\" and store it in a variable df\n",
    "df = pd.read_csv(\"data_fake_news_en.csv\")\n",
    "\n",
    "#print top 5 \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joLuZmFpT-fY",
    "outputId": "77d48614-f6b3-4227-e90e-dc8ddb17381b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'text', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Vérifier les noms des colonnes\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de split des données, mais vous pourrez utiliser n'importe quel moyen (bibliothèque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NjJqi7UBT-nr"
   },
   "outputs": [],
   "source": [
    "#import train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.text, \n",
    "    df.label, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=42,\n",
    "    stratify=df.label\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5lAD0iqGcdCn",
    "outputId": "4efb3c3c-0ad4-4501-d815-35a902095848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (35918,)\n",
      "Shape of X_test: (8980,)\n"
     ]
    }
   ],
   "source": [
    "#print the shapes of X_train and X_test\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 1** :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6h8ZZLxZd79"
   },
   "source": [
    "- Utiliser une représentation simple (CountVectorizer avec unigrams). (on supprime les mots vides, ...)\n",
    "- Utiliser un classifier de votre choix (par exemple **RandomForest**.\n",
    "- Afficher le rapport de classification \n",
    "\n",
    "\n",
    "**A TITRE INFICATIF voici le schéma que vous pourrez suivre**</br>\n",
    "Attention, l'exemple ci-dessous se base sur la biliothèque sklearn (ce n'est qu'un exemple);, vous pourrez utiliser n'importe quelle biliothèque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGg2iXv6g40l",
    "outputId": "3f895ca5-7606-4220-b9a2-7c26d9160a9b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 0. Choisir un classifieur, ici RandomForest\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 1. Transformer le texte en vecteurs de comptage (CountVectorizer)\n",
    "cv = CountVectorizer(\n",
    "    ngram_range=(1, 1),\n",
    "    stop_words='english',\n",
    "    max_features=5000,\n",
    "    min_df=2,\n",
    "    strip_accents='unicode',\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "# Transformer les données d'entraînement et de test\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "clf.fit(X_train_cv, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4696\n",
      "           1       1.00      1.00      1.00      4284\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Obtenir les prédictions pour X_test et les stocker dans y_pred\n",
    "y_pred = clf.predict(X_test_cv)\n",
    "\n",
    "# 4. Afficher le rapport de classification\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 2** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I08-kc_JYCNL"
   },
   "source": [
    "- Utiliser une représentation combinant unigrams et bi-grammes `CountVectorizer`\n",
    "- Utiliser un classifier de votre choix \n",
    "- Afficher le rapport de classification \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zetSmBrXmjM",
    "outputId": "b372f53c-8cbc-496f-ef4d-9fecff044230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4696\n",
      "           1       1.00      1.00      1.00      4284\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# définir le modèle\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "#1. create a  Transform text to countvectors \n",
    "\n",
    "cv_bigram = CountVectorizer(ngram_range=(1, 2),stop_words='english',max_features=5000,min_df=2,strip_accents='unicode',lowercase=True\n",
    ")\n",
    "\n",
    "#2. fit_ transform X_train (utiliser fit_transform de sklearn)\n",
    "\n",
    "X_train_cv_bigram = cv_bigram.fit_transform(X_train)\n",
    "X_test_cv_bigram = cv_bigram.transform(X_test)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "\n",
    "clf.fit(X_train_cv_bigram, y_train)\n",
    "y_pred = clf.predict(X_test_cv_bigram)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 3** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmrXmL_3Z2y6"
   },
   "source": [
    "- Utiliser **TF-IDF vectorizer**  avec unigrams.\n",
    "- Utiliser un classifier de votre choix \n",
    "- Afficher le rapport de classification \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djsDsThaaCSO",
    "outputId": "b4514ab2-f6ad-45e1-b91b-e88393e975e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      4696\n",
      "           1       0.98      0.99      0.99      4284\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import TfidfVectorizer from sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# définir le modèle\n",
    "clf = LogisticRegression(random_state=42)\n",
    "\n",
    "#1. Vectorise the Text \n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 1),stop_words='english',max_features=5000,min_df=2,strip_accents='unicode',lowercase=True)\n",
    "\n",
    "#2. fit (transform) with X_train \n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 4** :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9GZPaQbbJbx"
   },
   "source": [
    "- Représentation d'un texte avec des embeddings (word2vec ou BERT, ...).\n",
    "- Utiliser un classifier de votre choix (par exemple **RandomForest**.)\n",
    "- Afficher le rapport de classification \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2y1Cy4Bauxu",
    "outputId": "ac6bf255-a218-400c-c4a9-790f4a89dfb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      4696\n",
      "           1       0.98      0.98      0.98      4284\n",
      "\n",
      "    accuracy                           0.98      8980\n",
      "   macro avg       0.98      0.98      0.98      8980\n",
      "weighted avg       0.98      0.98      0.98      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import des librairies nécessaires\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "\n",
    "# Tokenisation des textes pour Word2Vec\n",
    "X_train_tokens = [text.split() for text in X_train]\n",
    "X_test_tokens = [text.split() for text in X_test]\n",
    "\n",
    "# Entraîner un modèle Word2Vec sur les données d'entraînement\n",
    "word2vec_model = Word2Vec(sentences=X_train_tokens, vector_size=100, window=5, min_count=1, workers=4, sg=0)\n",
    "\n",
    "# Fonction pour convertir un texte en un vecteur en moyennant les embeddings des mots\n",
    "def text_to_embedding(tokens, word2vec_model):\n",
    "    embeddings = [word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "#1. Transform text to tfidfvectorizer\n",
    "\n",
    "X_train_embeddings = np.array([text_to_embedding(tokens, word2vec_model) for tokens in X_train_tokens])\n",
    "X_test_embeddings = np.array([text_to_embedding(tokens, word2vec_model) for tokens in X_test_tokens])\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "#2. fit with X_train and y_train\n",
    "\n",
    "clf.fit(X_train_embeddings, y_train)\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "\n",
    "y_pred = clf.predict(X_test_embeddings)\n",
    "#4. print the classfication report\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Refaire le travail sur le Dataset en francais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset en francais "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Les chefs de service hospitaliers en appellent...</td>\n",
       "      <td>Jugeant très insuffisante la réponse du gouver...</td>\n",
       "      <td>Les chefs de service hospitaliers en appellent...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L'origine des comportements alimentaires ident...</td>\n",
       "      <td>D'après une étude publiée dans la revue</td>\n",
       "      <td>L'origine des comportements alimentaires ident...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Microsoft alerte sur de nouvelles techniques d...</td>\n",
       "      <td>Le géant de l'informatique Microsoft vient de ...</td>\n",
       "      <td>Microsoft alerte sur de nouvelles techniques d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L'Europe se dote d'une infrastructure de téléc...</td>\n",
       "      <td>Pour garantir la sécurité de la libre circulat...</td>\n",
       "      <td>L'Europe se dote d'une infrastructure de téléc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Science décalée : la créature la plus rapide s...</td>\n",
       "      <td>Le guépard est l'animal le plus rapide... sur ...</td>\n",
       "      <td>Science décalée : la créature la plus rapide s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Les chefs de service hospitaliers en appellent...   \n",
       "1  L'origine des comportements alimentaires ident...   \n",
       "2  Microsoft alerte sur de nouvelles techniques d...   \n",
       "3  L'Europe se dote d'une infrastructure de téléc...   \n",
       "4  Science décalée : la créature la plus rapide s...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Jugeant très insuffisante la réponse du gouver...   \n",
       "1           D'après une étude publiée dans la revue    \n",
       "2  Le géant de l'informatique Microsoft vient de ...   \n",
       "3  Pour garantir la sécurité de la libre circulat...   \n",
       "4  Le guépard est l'animal le plus rapide... sur ...   \n",
       "\n",
       "                                                text  fake  \n",
       "0  Les chefs de service hospitaliers en appellent...     0  \n",
       "1  L'origine des comportements alimentaires ident...     0  \n",
       "2  Microsoft alerte sur de nouvelles techniques d...     0  \n",
       "3  L'Europe se dote d'une infrastructure de téléc...     0  \n",
       "4  Science décalée : la créature la plus rapide s...     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importer la bibliothèque pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Lire le dataset avec le nom \"data_fake_news_fr\" et le stocker dans une variable df\n",
    "df = pd.read_csv(\"data_fake_news_fr.csv\")\n",
    "\n",
    "# Afficher les 5 premières lignes\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'description', 'text', 'fake'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Vérifier les noms des colonnes\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1945,)\n",
      "Shape of X_test: (487,)\n"
     ]
    }
   ],
   "source": [
    "# Importer train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.text, \n",
    "    df.fake,  # Utiliser la colonne 'fake' pour les labels\n",
    "    test_size=0.2,  # 20% des échantillons iront dans le dataset de test\n",
    "    random_state=42,\n",
    "    stratify=df.fake  # Assurer une stratification basée sur la colonne 'fake'\n",
    ")\n",
    "\n",
    "# Afficher les formes de X_train et X_test\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### QUESTION 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\simon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\simon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['etaient', 'etais', 'etait', 'etant', 'etante', 'etantes', 'etants', 'ete', 'etee', 'etees', 'etes', 'etiez', 'etions', 'eumes', 'eutes', 'fumes', 'futes', 'meme'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       273\n",
      "           1       0.95      0.95      0.95       214\n",
      "\n",
      "    accuracy                           0.96       487\n",
      "   macro avg       0.96      0.96      0.96       487\n",
      "weighted avg       0.96      0.96      0.96       487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Télécharger la liste des mots vides en français si ce n'est pas déjà fait\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Obtenir la liste des mots vides en français\n",
    "stop_words_fr = stopwords.words('french')\n",
    "\n",
    "# Choisir le classifieur, ici RandomForest\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Transformer le texte en vecteurs de comptage (CountVectorizer)\n",
    "cv = CountVectorizer(\n",
    "    ngram_range=(1, 1),\n",
    "    stop_words=stop_words_fr,  # Utiliser la liste de mots vides en français\n",
    "    max_features=5000,\n",
    "    min_df=2,\n",
    "    strip_accents='unicode',\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "# Transformer les données d'entraînement et de test\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "# Entraîner le modèle avec les données d'entraînement\n",
    "clf.fit(X_train_cv, y_train)\n",
    "\n",
    "# 3. Obtenir les prédictions pour X_test et les stocker dans y_pred\n",
    "y_pred = clf.predict(X_test_cv)\n",
    "\n",
    "# 4. Afficher le rapport de classification\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### QUESTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\simon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\simon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['etaient', 'etais', 'etait', 'etant', 'etante', 'etantes', 'etants', 'ete', 'etee', 'etees', 'etes', 'etiez', 'etions', 'eumes', 'eutes', 'fumes', 'futes', 'meme'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       273\n",
      "           1       0.94      0.97      0.95       214\n",
      "\n",
      "    accuracy                           0.96       487\n",
      "   macro avg       0.96      0.96      0.96       487\n",
      "weighted avg       0.96      0.96      0.96       487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import nltk\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Télécharger les stopwords en français de nltk\n",
    "nltk.download('stopwords')\n",
    "french_stopwords = stopwords.words('french')\n",
    "\n",
    "# Définir le modèle (ici, RandomForest)\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 1. Créer un CountVectorizer pour transformer le texte en vecteurs de comptage (unigrams et bigrams)\n",
    "cv_bigram = CountVectorizer(\n",
    "    ngram_range=(1, 2),  # Utiliser des unigrams et bigrams\n",
    "    stop_words=french_stopwords,  # Utiliser les mots vides en français\n",
    "    max_features=5000,  # Limiter à 5000 mots les plus fréquents\n",
    "    min_df=2,  # Ignorer les mots qui apparaissent dans moins de 2 documents\n",
    "    strip_accents='unicode',  # Supprimer les accents\n",
    "    lowercase=True  # Convertir tout en minuscules\n",
    ")\n",
    "\n",
    "# 2. Appliquer fit_transform sur X_train\n",
    "X_train_cv_bigram = cv_bigram.fit_transform(X_train)\n",
    "X_test_cv_bigram = cv_bigram.transform(X_test)\n",
    "\n",
    "# 3. Entraîner le modèle avec les données d'entraînement\n",
    "clf.fit(X_train_cv_bigram, y_train)\n",
    "\n",
    "# 4. Obtenir les prédictions pour X_test et les stocker dans y_pred\n",
    "y_pred = clf.predict(X_test_cv_bigram)\n",
    "\n",
    "# 5. Afficher le rapport de classification\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### QUESTION 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\simon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\simon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['etaient', 'etais', 'etait', 'etant', 'etante', 'etantes', 'etants', 'ete', 'etee', 'etees', 'etes', 'etiez', 'etions', 'eumes', 'eutes', 'fumes', 'futes', 'meme'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       273\n",
      "           1       0.93      0.93      0.93       214\n",
      "\n",
      "    accuracy                           0.94       487\n",
      "   macro avg       0.94      0.94      0.94       487\n",
      "weighted avg       0.94      0.94      0.94       487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "french_stopwords = stopwords.words('french')\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "\n",
    "# 1. Vectoriser le texte avec TF-IDF (uniquement des unigrams)\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 1),  \n",
    "    stop_words=french_stopwords,  \n",
    "    max_features=5000, \n",
    "    min_df=2,  \n",
    "    strip_accents='unicode',  \n",
    "    lowercase=True  \n",
    ")\n",
    "\n",
    "# 2. Appliquer fit_transform sur X_train\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# 3. Entraîner le modèle avec les données d'entraînement\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 4. Obtenir les prédictions pour X_test et les stocker dans y_pred\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "# 5. Afficher le rapport de classification\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### QUESTION 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\simon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\simon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90       273\n",
      "           1       0.87      0.86      0.87       214\n",
      "\n",
      "    accuracy                           0.88       487\n",
      "   macro avg       0.88      0.88      0.88       487\n",
      "weighted avg       0.88      0.88      0.88       487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importer les librairies nécessaires\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')  \n",
    "\n",
    "# Tokenisation des textes pour Word2Vec\n",
    "X_train_tokens = [word_tokenize(text.lower()) for text in X_train]  # Convertir en minuscules et tokeniser\n",
    "X_test_tokens = [word_tokenize(text.lower()) for text in X_test]    # Convertir en minuscules et tokeniser\n",
    "\n",
    "# Entraîner un modèle Word2Vec sur les données d'entraînement\n",
    "word2vec_model = Word2Vec(sentences=X_train_tokens, vector_size=100, window=5, min_count=1, workers=4, sg=0)\n",
    "\n",
    "# Fonction pour convertir un texte en un vecteur en moyennant les embeddings des mots\n",
    "def text_to_embedding(tokens, word2vec_model):\n",
    "    embeddings = [word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "# 1. Convertir les textes en embeddings\n",
    "X_train_embeddings = np.array([text_to_embedding(tokens, word2vec_model) for tokens in X_train_tokens])\n",
    "X_test_embeddings = np.array([text_to_embedding(tokens, word2vec_model) for tokens in X_test_tokens])\n",
    "\n",
    "# Définir le classificateur RandomForest\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 2. Entraîner le modèle avec X_train_embeddings et y_train\n",
    "clf.fit(X_train_embeddings, y_train)\n",
    "\n",
    "# 3. Obtenir les prédictions pour X_test et les stocker dans y_pred\n",
    "y_pred = clf.predict(X_test_embeddings)\n",
    "\n",
    "# 4. Afficher le rapport de classification\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tf_idf_exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
